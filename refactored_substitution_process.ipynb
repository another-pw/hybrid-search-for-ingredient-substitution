{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from pathlib import Path\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'word2vec' # select between [bert, splade, word2vec]\n",
    "\n",
    "bert_model_path = 'path/to/bert_model_folder'\n",
    "splade_model_path = 'path/to/splade_model_folder'\n",
    "word2vec_model_path = 'path/to/word2vec_model.bin'\n",
    "\n",
    "# initiate model\n",
    "if model_name == 'bert':\n",
    "    model = AutoModelForMaskedLM.from_pretrained(pretrained_model_name_or_path=bert_model_path)\n",
    "elif model_name == 'splade':\n",
    "    model = AutoModelForMaskedLM.from_pretrained(pretrained_model_name_or_path=splade_model_path)\n",
    "elif model_name == 'word2vec':\n",
    "    model = Word2Vec.load(word2vec_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Ingredient Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Helper Functions for BERT and SPLADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dense_vector(text, tokenizer, model):\n",
    "    tokens = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens, output_hidden_states=True)\n",
    "        last_hidden_state = outputs.hidden_states[-1]\n",
    "        dense_vector = last_hidden_state[:, 1, :].squeeze()\n",
    "    \n",
    "    return dense_vector.tolist()\n",
    "\n",
    "def generate_sparse_vector(text, tokenizer, model):\n",
    "    tokens = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**tokens)\n",
    "    sparse_vector = torch.max(\n",
    "        torch.log(1 + torch.relu(output.logits)) * tokens.attention_mask.unsqueeze(-1), \n",
    "        dim=1,\n",
    "    )[0].squeeze()\n",
    "    \n",
    "    return sparse_vector.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating ingredient embeddings using 'word2vec': 100%|██████████| 7006/7006 [00:00<00:00, 437606.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salt: [ 5.290445    0.913867   -1.0863012   0.8623626  -0.4674062   1.4850291\n",
      " -4.449398    0.19326593  0.79840225 -3.7696817  -8.937332    5.396243\n",
      " -1.5825946   3.3089976   0.90930027  0.60248166  1.1192898   2.095074\n",
      " -0.53546184  1.9280357   6.0514913  -0.2811899  -6.5449524   1.2315501\n",
      " -2.2797735   2.9715595  -5.8430834   1.6902156   2.910913    5.693375\n",
      " -0.930088   -2.8069067  -0.13160013 -6.9677563  -0.65470976 -1.4642285\n",
      " -6.432981    0.97264045 -2.9176748  -7.265186   -4.413367   -4.1855135\n",
      "  0.36481628 -4.518372   -3.1976647  -1.7128602   0.5032585   5.3611813\n",
      " -3.8773909  -0.6008178   3.7304778  -3.2806964   3.2925324  -5.261976\n",
      "  1.495242   -0.7740897   3.0662649  -3.4892735  -2.044665    5.276503\n",
      " -0.08387772  1.8251109   1.8781763  -6.6783423  -3.9808152   0.18981819\n",
      "  1.9181858  -1.3713095  -3.5619245  -1.8910278   2.3206096   1.0558263\n",
      " -0.85360146 -0.86032116 -0.766023    4.740972   -4.9475346  -0.9059874\n",
      " -2.213351    1.6304389  -2.3757186  -7.375565    3.9031565   1.3749194\n",
      " -0.23636207  7.3833375   1.3272098  -0.19721147  0.44422972 -1.0779055\n",
      "  1.9828022   1.344008   -3.5656726   0.8700991  -3.0440328   0.48125464\n",
      "  5.275027    3.6180935  -3.13406    -4.395787  ]\n",
      "butter: [ 2.9879322   6.094846    0.9093871   2.1312847  -4.4753723  -5.551116\n",
      " -1.915168    2.6743011   3.549476    6.034867   -6.0860915   3.7163088\n",
      " -2.8723001   0.83700347 -2.9789505   5.770747   -1.1390848   0.6667993\n",
      "  1.2436392   2.7144775   4.075457    1.3496234  -4.0315876   2.788028\n",
      " -0.22766332  0.9454888   3.711968    0.42790323  0.22440085 -0.8433476\n",
      " -1.5758294  -1.216293    3.9903898  -3.8263056   0.58676046  2.4572055\n",
      " -5.334562    4.9854403   0.05754783 -1.9064568  -2.296207    1.4648861\n",
      " -4.4124384  -4.100939    0.6293773   0.06439262 -1.6990298   0.68078375\n",
      "  1.4595735  -2.7528262   2.8733444  -0.01332202  3.4863803  -0.5081467\n",
      " -0.13817479 -3.231178    3.8661072  -2.8373709  -0.2872787   3.2583492\n",
      "  1.4171332  -0.3465917   0.27814904  0.43200192 -1.4088072   1.4290044\n",
      " -0.7744445  -6.039903    1.145939   -0.39487857 -0.02364759 -2.6251447\n",
      "  1.6932403  -1.4423968   4.7798266   1.4066886   1.0968261   3.500845\n",
      " -3.848799   -3.5095682   2.13305     6.1825166   0.04341078 -2.2909088\n",
      "  2.3415048  -0.9771214   2.123924   -5.229125    1.70863    -0.39775178\n",
      "  1.0783228  -0.23943199 -0.4471261   4.285107    2.5364115   4.5649633\n",
      "  0.15823057 -0.5344567   3.0904958  -0.04323447]\n",
      "sugar: [-0.60194355  4.3740606   1.1578965   1.253343   -5.384068    2.5589595\n",
      " -0.36796352 -3.3354518   1.8719679  -3.0471387  -0.30061775  5.6156\n",
      " -1.041226    1.888092    0.59052205  1.7964153  -2.3269181   3.0875\n",
      "  7.4694753   6.9865923  -0.24105714  2.940396   -3.6743262  -0.5517214\n",
      "  0.484971    2.1375065  -2.1532388   2.128356   -1.5544018  -2.1092408\n",
      " -3.618006    1.0092338   1.3760557   0.42743656  2.3965654   1.9132191\n",
      " -1.9590077   1.2289971  -6.6377106  -1.5425456  -3.9281585  -8.216168\n",
      " -4.757086    2.3673663   2.3655589   1.6437918   4.6517534   5.376628\n",
      " -2.6550224  -1.3547579   3.244183   -2.0659816   2.6470041  -3.233503\n",
      " -4.565472   -2.6374106   5.742213    0.4135187   0.25710198  6.411227\n",
      "  1.553173   -3.8284178   5.298442   -3.2117226   1.66878     0.6693096\n",
      " -6.1146545  -4.997232    2.703241   -1.7059256   2.0360866   1.9743072\n",
      "  0.94525146 -2.070244    3.8537793  -0.3382696  -5.921151   -3.75557\n",
      " -7.26309     1.7037804  -1.8549708   3.4904974  -4.586973   -1.8219448\n",
      " -4.967707    2.7804637   1.4109609  -1.5259925   2.2995107  -2.2128665\n",
      "  2.0938962   1.9301951   4.5593934   2.8986518   2.3180091   2.6111403\n",
      "  1.1118383  -3.0211053  -1.5511459  -0.83338547]\n",
      "water: [-1.0831032   2.7656338  -3.7007508  -0.36497125 -1.4616603  -4.505058\n",
      " -6.3002124   4.0415616  -3.4274714  -4.871943   -0.5453261  -2.723788\n",
      " -0.57870764 -0.10721856  1.8595532  -2.755933   -3.833522    1.4160299\n",
      "  1.8167158  -1.3970784   0.32730073 -1.0148283  -5.367642   -1.7156504\n",
      "  1.8852082   2.842598    0.3623161   2.6081107   2.4100018  -1.3531026\n",
      "  0.12892865 -5.7120085   3.600628   -6.0379667   2.336533    1.0464228\n",
      " -0.88911664 -3.0491195  -2.0011852   0.16673192 -3.6054473   2.3743556\n",
      " -7.5470552   3.7773757   4.283733    6.981969   -0.34368756 -3.7065744\n",
      " -8.206734   -1.6852678   6.458685    1.8440682   4.5385957  -3.724332\n",
      " -1.9771836   2.3397326   3.9884343  -0.41355726  4.584789    5.8859377\n",
      "  3.9632003   3.5000923  -0.41329557 -5.682344   -0.35099685 -5.5874333\n",
      " -4.6022406  -1.9038361  -1.5005977   0.11520854 -0.711685   -0.26424712\n",
      "  0.13662352 -5.402241    1.227973    1.9513793  -2.9841688  -1.7088677\n",
      "  3.1016374   0.7345371   4.533148    3.319905    3.9172504  -0.60841995\n",
      " -4.5614595  -2.7500474   3.8920362   1.5865074   2.1143591   1.1490791\n",
      "  6.144909    3.0569367   0.671049    3.442084   -1.1413031   4.969303\n",
      "  3.8456173   2.1931171  -2.1354852   1.016326  ]\n",
      "top: [-1.0466944  -4.613636   -2.7985187   0.55624056  0.01627049  3.422293\n",
      "  0.45451564 11.088216    1.2601956   5.7846766  -2.1603196   3.0147846\n",
      " -3.7909465   0.34250072  5.0564604  -0.6139286  -3.9687605  -1.1939892\n",
      " -0.5737157  -0.01360914 -4.3205705  -3.6225789  -0.05918845  5.4918685\n",
      " -2.9767065   2.1408012   1.6325144  -3.8776846   1.4789373  -0.8484189\n",
      " -0.24118005 -1.5867727   2.271176    0.42772177 -3.1416333  -4.024726\n",
      " -0.28148577 -4.208478   -0.64190876 -1.381709    5.126101    2.8435502\n",
      "  2.2160413  -3.5007596  -4.9579706   5.235138   -2.2259862   2.419781\n",
      "  3.0418456   2.4248538   0.8191306  -3.2070131  -4.7916408   5.612964\n",
      " -8.283134   -2.9440978   1.6208533   4.6325035  -3.421139   -4.123625\n",
      " -4.6771283   2.990866    1.4990157   3.2333877  -4.6637864  -0.49491802\n",
      " -4.437838    1.1880693  -2.5974648   1.3976732   3.4313946  -0.28970206\n",
      "  4.121443    7.6314473   3.208693    0.36107343 -2.4595542  -1.4730968\n",
      "  0.3282226   3.4658647   1.2556849  -4.342996    3.71199     0.2670652\n",
      "  1.1871121  -0.12665421  1.4551804   0.6418462  -3.404862    0.66406775\n",
      "  2.268671    3.2616246  -0.39751533  1.3271391  -0.53266054 -4.865892\n",
      " -3.8270042  -1.1748462  -0.38433522  0.5591946 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "GENERATING_EMBEDDING_MESSAGE = f\"generating ingredient embeddings using '{model_name}'\"\n",
    "\n",
    "vocab_file = 'path/to/bert-base-cased-vocab.txt' # bert-base-cased-vocab file path\n",
    "used_ingredients_file = 'path/to/all_ingredients.json' # cleaned ingredients file path\n",
    "\n",
    "with Path(used_ingredients_file).open() as f:\n",
    "    used_ingredients = json.load(f)\n",
    "\n",
    "ingredient_names = []\n",
    "ingredient_embeddings = []\n",
    "\n",
    "if model_name == 'bert' or model_name == 'splade':\n",
    "    tokenizer = BertTokenizer(\n",
    "        vocab_file=vocab_file, \n",
    "        do_lower_case=False,\n",
    "        max_len=128,\n",
    "        never_split=used_ingredients\n",
    "    )\n",
    "\n",
    "    for ingredient in tqdm(used_ingredients, desc=GENERATING_EMBEDDING_MESSAGE):\n",
    "        if model_name == 'bert':\n",
    "            embedding = generate_dense_vector(text=ingredient, tokenizer=tokenizer, model=model)\n",
    "        elif model_name == 'splade':\n",
    "            embedding = generate_sparse_vector(text=ingredient, tokenizer=tokenizer, model=model)\n",
    "        \n",
    "        ingredient_names.append(ingredient)\n",
    "        ingredient_embeddings.append(embedding)\n",
    "\n",
    "elif model_name == 'word2vec':\n",
    "    for ingredient in tqdm(used_ingredients, desc=GENERATING_EMBEDDING_MESSAGE):\n",
    "        try:\n",
    "            embedding = model.wv[ingredient]\n",
    "            ingredient_names.append(ingredient)\n",
    "            ingredient_embeddings.append(embedding)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "preview_top_n = 5\n",
    "for i in range(preview_top_n):\n",
    "    print(f'{ingredient_names[i]}: {ingredient_embeddings[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search Similarity Between Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "finding closest ingredients...:   0%|          | 0/6988 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "finding closest ingredients...: 100%|██████████| 6988/6988 [00:13<00:00, 537.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salt: [('kosher_salt', 19.65060806274414), ('salt_black', 21.303600311279297), ('sea_salt', 21.42864227294922), ('garlic_salt', 22.803667068481445), ('coarse_salt', 25.142929077148438), ('butter_salt', 25.47328758239746), ('rosemary_salt', 25.72801399230957), ('seasoning_salt', 25.76896095275879), ('pepper_salt', 26.266878128051758), ('onion_salt', 26.509910583496094)]\n",
      "butter: [('margarine', 17.67350196838379), ('unsalted_butter', 20.01671600341797), ('oleo', 20.376522064208984), ('softened_butter', 20.44024658203125), ('shortening', 20.800329208374023), ('butter_oil', 21.83688735961914), ('coconut_oil', 22.075387954711914), ('melted_butter', 22.215559005737305), ('crisco', 23.806915283203125), ('lard', 23.95610809326172)]\n",
      "sugar: [('granulated_sugar', 18.866891860961914), ('brown_sugar', 18.93625259399414), ('white_sugar', 22.164108276367188), ('confectioner_sugar', 24.371112823486328), ('honey', 24.801908493041992), ('caster_sugar', 25.418663024902344), ('powdered_sugar', 25.85028839111328), ('splenda', 25.93134307861328), ('vanilla_sugar', 26.02912712097168), ('almond_extract', 26.100507736206055)]\n",
      "water: [('hot_water', 21.662681579589844), ('cold_water', 21.683795928955078), ('warm_water', 23.879981994628906), ('boiling_water', 24.639535903930664), ('salt_water', 26.746870040893555), ('chicken_stock', 26.778348922729492), ('broth', 27.491134643554688), ('stock', 27.572650909423828), ('chicken_broth', 27.641984939575195), ('cold_milk', 28.82530403137207)]\n",
      "top: [('base', 29.25864601135254), ('pepperoni_slice', 29.68592071533203), ('toasted_bun', 29.69830322265625), ('hoagie_roll', 29.914491653442383), ('provolone_cheese', 30.167335510253906), ('burrata', 30.271371841430664), ('kaiser_rolls', 30.285442352294922), ('sliced_tomato', 30.323501586914062), ('camembert', 30.342777252197266), ('bread_roll', 30.396108627319336)]\n"
     ]
    }
   ],
   "source": [
    "result_export_path = 'path/to/export/result.json'\n",
    "\n",
    "n_neighbors = 10\n",
    "neighbors = NearestNeighbors(n_neighbors=n_neighbors, n_jobs=-1)\n",
    "neighbors.fit(ingredient_embeddings)\n",
    "\n",
    "results = {}\n",
    "for i in tqdm(range(len(ingredient_embeddings)), desc='finding closest ingredients...'):\n",
    "    distance, indices = neighbors.kneighbors(\n",
    "        [ingredient_embeddings[i]], \n",
    "        n_neighbors + 1,\n",
    "        return_distance=True\n",
    "    )\n",
    "\n",
    "    substitutes_and_scores = []\n",
    "    # map nearest neighbor indices to ingredient names and create substitution results\n",
    "    for j, idx in enumerate(indices[0]):\n",
    "        if ingredient_names[i] != ingredient_names[idx]:\n",
    "            substitutes_and_scores.append(((ingredient_names[idx], distance[0][j])))\n",
    "    \n",
    "    results[ingredient_names[i]] = substitutes_and_scores[:n_neighbors]\n",
    "\n",
    "preview_top_n = 5\n",
    "for i in range(preview_top_n):\n",
    "    print(f'{ingredient_names[i]}: {results[ingredient_names[i]]}')\n",
    "\n",
    "# save first-stage results\n",
    "with Path(result_export_path).open('w') as file:\n",
    "    json.dump(results, file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fusion 2 Results And Filter Thai Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank_fusion(list1, list2):\n",
    "    reciprocal_ranks = {}\n",
    "\n",
    "    for sublist in [list1, list2]:\n",
    "        for i, item in enumerate(sublist):\n",
    "            rank = i + 1\n",
    "            reciprocal_rank = 1 / rank\n",
    "            if item[0] in reciprocal_ranks:\n",
    "                reciprocal_ranks[item[0]] += reciprocal_rank\n",
    "            else:\n",
    "                reciprocal_ranks[item[0]] = reciprocal_rank\n",
    "    \n",
    "    for item in reciprocal_ranks.keys():\n",
    "        reciprocal_ranks[item] /= 2\n",
    "\n",
    "    merged_list = sorted(reciprocal_ranks.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return merged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "merging results...: 100%|██████████| 7006/7006 [00:00<00:00, 75720.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accompaniment', 'orange')\n",
      "('accompaniment', 'shallot')\n",
      "('ada', 'cassava')\n",
      "('alcoholic_beverage', 'nightshade')\n",
      "('allspice', 'cardamom')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result_1_path = 'path/to/result.json'\n",
    "result_2_path = 'path/to/result.json'\n",
    "merged_result_export_path = 'path/to/export/merged_result.json'\n",
    "\n",
    "thai_ingredients_path = 'path/to/thai_ingredients.json'\n",
    "\n",
    "with Path(result_1_path).open() as f:\n",
    "    result_1 = json.load(f)\n",
    "\n",
    "with Path(result_2_path).open() as f:\n",
    "    result_2 = json.load(f)\n",
    "\n",
    "with Path(thai_ingredients_path).open() as file:\n",
    "    thai_ingredients = json.load(file)\n",
    "    thai_ingredients_set = set(thai_ingredients)\n",
    "\n",
    "top_k = 5\n",
    "subtitute_pairs = set()\n",
    "for key in tqdm(result_1.keys(), desc='merging results...'):\n",
    "    if key in result_1 and key in result_2:\n",
    "        # fusion 2 results into a single result\n",
    "        merged_list = reciprocal_rank_fusion(result_1[key], result_2[key])\n",
    "        # filter only Thai ingredients in the final result\n",
    "        for item, score in merged_list[:top_k]:\n",
    "            if item.replace('_', ' ') in thai_ingredients_set:\n",
    "                subtitute_pairs.add((key.replace('_', ' '), item.replace('_', ' ')))\n",
    "\n",
    "subtitute_pairs = list(sorted(subtitute_pairs))\n",
    "\n",
    "preview_top_n = 5\n",
    "for i in range(preview_top_n):\n",
    "    print(f'{subtitute_pairs[i]}')\n",
    "\n",
    "# save the final substitution results\n",
    "with open(merged_result_export_path, 'w') as file:\n",
    "    json.dump(subtitute_pairs, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
